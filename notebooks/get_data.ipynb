{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b50d3bb",
   "metadata": {},
   "source": [
    "## Data Acquisition\n",
    "\n",
    "We are ultimately interested in testing the following hypothesis:\n",
    "> **Centrist individuals exhibit lower levels of affective polarization.**\n",
    "\n",
    "The goal of this notebook is to **acquire, clean, and prepare** a dataset that allows us to empirically examine this hypothesis using survey data. Specifically, we will extract a reduced set of variables from the ESS Round 10 dataset, rename them for clarity, and conduct a brief exploratory analysis.\n",
    "\n",
    "This notebook will output a **smaller dataset well-documented, and analysis-ready dataset** containing only the variables relevant for testing the hypothesis.\n",
    "\n",
    "### Work Plan\n",
    "\n",
    "1. Load the ESS Round 10 dataset *(already completed)*\n",
    "2. Identify the variables relevant for our hypothesis\n",
    "3. Create a subset dataframe containing only these variables\n",
    "4. Rename variables using clear and descriptive names\n",
    "5. Produce basic summary statistics for each selected variable\n",
    "6. Export the cleaned dataset as a temporary CSV file\n",
    "\n",
    "### Tips\n",
    "\n",
    "- You should adapt code from previous notebooks, such as:\n",
    "    - `04-data-exploration-columns.ipynb` (mostly)\n",
    "    - `subset_dataframes.ipynb` (but also)\n",
    "\n",
    "- You can also consult the **typst article** to help you identify theoretically relevant variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97447917",
   "metadata": {},
   "source": [
    "## Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d856337d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Relevant Libraries/Packages/Modules\n",
    "import os\n",
    "import requests\n",
    "import zipfile\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af225c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing Relevant Paths & Folders\n",
    "file_url = \"https://github.com/datamisc/ess-10/raw/main/data.zip\"\n",
    "data_dir = \"data/raw/\"\n",
    "# Check if data directory exists\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "# Filenames\n",
    "csv_filename = \"ESS10.csv\"\n",
    "zip_path = os.path.join(data_dir, \"data.zip\")\n",
    "csv_path = data_dir + csv_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0475fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to download the dataset if not available\n",
    "def get_data():\n",
    "    if os.path.exists(csv_path):\n",
    "        print(f\"‚úÖ CSV already exists: {csv_path}\")\n",
    "        return\n",
    "\n",
    "    print(\"‚ùó CSV not found. Downloading ZIP...\")\n",
    "\n",
    "    # Download ZIP\n",
    "    response = requests.get(file_url)\n",
    "    response.raise_for_status()\n",
    "    with open(zip_path, \"wb\") as f:\n",
    "        f.write(response.content)\n",
    "    print(f\"üì¶ ZIP downloaded to: {zip_path}\")\n",
    "\n",
    "    # Extract ZIP\n",
    "    print(\"üìÇ Extracting ZIP...\")\n",
    "    with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
    "        zip_ref.extractall(data_dir)\n",
    "\n",
    "    print(f\"‚úÖ Files extracted to: {data_dir}\")\n",
    "\n",
    "    # Confirm extraction\n",
    "    if not os.path.exists(csv_path):\n",
    "        raise FileNotFoundError(\n",
    "            f\"CSV '{csv_filename}' not found inside ZIP. \"\n",
    "            f\"Check ZIP contents in {data_dir}.\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d42843",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the newly created `get_data()` function.\n",
    "get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1cfc47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the raw CSV data into a `df_raw` object that you keep as a backup\n",
    "df_raw = pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087988ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a look at the data you just loaded\n",
    "df_raw\n",
    "# or \n",
    "df_raw.head()\n",
    "# or \n",
    "df_raw.sample(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322ac157",
   "metadata": {},
   "source": [
    "# Relevant Variables/Columns\n",
    "- You need to check the codebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1ce887",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list with the names of the relevant variables\n",
    "vars_1 = [\"vote\", \"cntry\", \"prtvtefr\", \"prtclffr\", \"prtdgcl\", \"lrscale\"]\n",
    "vars_2 = [\"lrscale\", \"clsprty\", \"prtdgcl\", \"cntry\", \"prtclffr\", \"prtvtefr\"]\n",
    "\n",
    "# or ?\n",
    "\n",
    "vars = [\n",
    "    \"clsprty\", \n",
    "    \"cntry\",  # country\n",
    "    \"lrscale\",  # this needs to be recoded\n",
    "    \"prtclffr\",  # some comment to explain this is closer to a party\n",
    "    \"prtdgcl\",\n",
    "    \"prtvtefr\",\n",
    "    \"vote\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8816b09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6dbb981",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You could also use a dictionnary (more on this later...)\n",
    "\n",
    "vars_dict = {\n",
    "    \"clsprty\": \"closer_party_dummy\",\n",
    "    \"cntry\": \"country\",\n",
    "    \"lrscale\": \"ideology\",\n",
    "    \"prtclffr\": \"closer_party\",\n",
    "    \"prtdgcl\": \"closer_party_likert\", \n",
    "    \"prtvtefr\": \"previous_vote\",\n",
    "    \"vote\": \"vote\",\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04a1a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_dict.keys()    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da61d48",
   "metadata": {},
   "source": [
    "# Data Subset\n",
    "Use the previous list to create a new data frame called `df` containing only the relevant columns from `df_raw`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21cff964",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe with the selected variables\n",
    "df = df_raw[vars]\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd526f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[vars_dict.keys()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0a0cf6",
   "metadata": {},
   "source": [
    "# Rename Variables \n",
    "Create a list of meaningful column names and assign it to `df.columns` to rename the DataFrame columns.\n",
    "- Remember to use lowercase underscore to name the columns (also called snake_case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f996ee99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns\n",
    "col_names =[\n",
    "    \"closer_party_dummy\",\n",
    "    \"country\",\n",
    "    \"ideology\",\n",
    "    \"closer_party\",\n",
    "    \"closer_party_likert\", \n",
    "    \"previous_vote\",\n",
    "    \"vote\"\n",
    "]\n",
    "df.columns = col_names\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eddcd246",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or using the previously created dictionnary\n",
    "df = df.rename(columns=vars_dict)  # The advantage is that the order doesn't matter. It matches the keys!\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dcab092",
   "metadata": {},
   "source": [
    "# Summary Statistics\n",
    "You will likely use some of the following methods to quickly explore your dataset:\n",
    "- `df.info()` to inspect data types and missing values\n",
    "- `df['some_continuous_var'].describe()` to summarize a continuous variable\n",
    "- `df['some_discrete_var'].value_counts()` to examine the distribution of a discrete variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213b9d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f9e266",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You could go 1 by 1\n",
    "df['closer_party_dummy'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340de1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or take a deeper look at a specif numeric variable\n",
    "df['closer_party_dummy'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed84fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# But you can also check them all together if you have just a few columns\n",
    "# This selects all numeric columns\n",
    "df.select_dtypes(include=\"number\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353efc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then we use the describe method\n",
    "df.select_dtypes(include=\"number\").describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18036158",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can do the same for \"string\" or categorical variables\n",
    "df.select_dtypes(include=\"str\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175b5d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# But for categorical/nominal variables we usually want to count things\n",
    "df.select_dtypes(include=\"object\").value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2686724",
   "metadata": {},
   "source": [
    "# Save the Data\n",
    "Save the cleaned DataFrame to a CSV file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb57c7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e359cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can you figure this out? Don't forget to set the `index` argument to False\n",
    "df.to_csv(\"data/ess_subset.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paper-spsc-2026 (3.13.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
